{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIaOqtkBOQDN"
   },
   "source": [
    "# Get data from twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AJpatZ_gN-1s"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import networkx\n",
    "from textblob import TextBlob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yvgkRDp6PFH"
   },
   "source": [
    "# snscrape Playground"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TW5cu8-pZpAh",
    "outputId": "011667fb-f767-4648-f4a8-41bedb3666fc"
   },
   "source": [
    "!pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yYugn7hA6SV9"
   },
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZS6sf-RwHt1"
   },
   "source": [
    "# snscrape GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGJs6QxHwL14"
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jUFLmIvPwUw_"
   },
   "outputs": [],
   "source": [
    "#Define functions\n",
    "\n",
    "def list_to_df(liste):\n",
    "  # Create corpus.\n",
    "  corpus = pd.DataFrame(liste, columns = ['date','id','tweet','user'])\n",
    "  # Set Turkey timezone.\n",
    "  eastern = pytz.timezone('Turkey')\n",
    "  corpus['date'] = corpus['date'].dt.tz_convert(eastern)\n",
    "  print(\"DONE: List converted to dataframe.\")\n",
    "  return corpus\n",
    "\n",
    "def df_to_csv(corpus,file_name = 'result.csv'):\n",
    "  corpus.to_csv(file_name, sep='æ', encoding='utf-8-sig', index = None)  # use æ unique operator to avoid confusion. \n",
    "  print(\"DONE: File written. File name ->  \" + file_name) \n",
    "\n",
    "def set_language(lang):\n",
    "  if lang == \"\":\n",
    "    return lang\n",
    "  return 'lang:'+lang + ' '\n",
    "  \n",
    "def get_date(d):\n",
    "  d = str(d.strftime('%d/%m/%Y %H:%M'))\n",
    "  return d\n",
    "\n",
    "def write_start_end_time(start_time, end_time):\n",
    "  start_time = str(start_time.strftime('%d/%m/%Y %H:%M:%S'))\n",
    "  end_time = str(end_time.strftime('%d/%m/%Y %H:%M:%S'))\n",
    "  return start_time, end_time\n",
    "\n",
    "def create_query(searched_word,excepted_word,replies, language, start_time,end_time):\n",
    "  if(excepted_word == \"\"):\n",
    "    pass\n",
    "  else: \n",
    "    excepted_word_list = excepted_word.split(' ')\n",
    "    excepted_word = \"\"\n",
    "    for ex in excepted_word_list:\n",
    "      excepted_word = excepted_word + \"-\" + ex +\" \"\n",
    "\n",
    "  if replies == \"n\":\n",
    "    replies = \"-filter:replies\"\n",
    "  else: \n",
    "    replies = \"\"\n",
    "  \n",
    "  language = set_language(language)\n",
    "  start_time = \"since:\"+start_time\n",
    "  end_time = \"until:\"+end_time\n",
    "\n",
    "  query = searched_word + \" \" + excepted_word + language + start_time + \" \" + end_time + \" \" + replies\n",
    "  return query\n",
    "\n",
    "def search_tweets(search_query, limitation,file_name):\n",
    "  tweets = []\n",
    "  start_time = datetime.now()\n",
    "  counter = 1\n",
    "  print(\"Tweet scraping started.\")\n",
    "  for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_query).get_items()):\n",
    "    if limitation == 0:\n",
    "      pass\n",
    "    elif i > limitation: # Runtime is 2 mins for 5000 tweets. Try small number for test. \n",
    "      break\n",
    "    counter += 1\n",
    "    date = tweet.date\n",
    "    date = get_date(date)\n",
    "    if counter % 1000 == 0: print(counter) # 1 output per 50 tweets.\n",
    "    tweets.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
    "\n",
    "  print(\"Tweet scraping finished.\")\n",
    "  print(\"___________________________________________________________________\")\n",
    "  end_time = datetime.now()\n",
    "  start_time, end_time = write_start_end_time(start_time,end_time)\n",
    "  print('Start time: %25s\\nEnd time: %29s\\nTotal tweets: %7s'%(start_time,end_time,counter))\n",
    "  if file_name == \"\":\n",
    "    df_to_csv(list_to_df(tweets)) #df_to_csv(list_to_df(tweets),'yeni_csv_adi.csv')\n",
    "  else: \n",
    "    file_name = file_name + '.csv'\n",
    "    df_to_csv(list_to_df(tweets), file_name)\n",
    "  print(\"___________________________________________________________________\") \n",
    "\n",
    "def collect_tweets():\n",
    "  searched_word = input(\"Word to search: \")\n",
    "  excepted_word = input(\"Words to exclude (must have a space between words) : \")\n",
    "  replies = input(\"Include answers? (default 'n') y/n?: \")\n",
    "  language = input(\"For any language limitation, write it as shortening\\nExample; for Turkish 'tr'\\nfor English 'en'\\nfor French 'fr'\\nIf you don't want any limitation, leave empty: \")\n",
    "  \n",
    "  start_time = input(\"Start time? (YYYY-MM-DD 2022-01-01): \")\n",
    "  end_time = input(\"End time? (YYYY-MM-DD 2022-01-31): \")\n",
    "  limitation = int(input(\"Do you want any limitations? If you don't want it, write 0: \"))\n",
    "  return searched_word, excepted_word, replies, language, start_time, end_time, limitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4glG1HTa0Mfj",
    "outputId": "13190367-bf04-4e49-a730-6b3df872dc8e"
   },
   "outputs": [],
   "source": [
    "#Collect Data#\n",
    "word_to_search = \"\"\n",
    "word_to_exclude = \"\"\n",
    "replies_included = \"n\"\n",
    "language = \"\"\n",
    "start_time_date = \"\"\n",
    "end_time_date = \"\"\n",
    "search_query = \"\"\n",
    "limitation = 0\n",
    "#### Program Started ####\n",
    "print(\"___________________________________________________________________\")\n",
    "word_to_search, word_to_exclude, replies_included, language, start_time_date, end_time_date, limitation = collect_tweets()\n",
    "print(\"___________________________________________________________________\")\n",
    "search_query = create_query(word_to_search,word_to_exclude,replies_included,language, start_time_date, end_time_date)\n",
    "print(\"Seacrh query:\", search_query)\n",
    "file_name = input(\"Use a specific filename? \\nIf you leave it blank it will overwrite 'tweet_data' .\\nFile name: \")\n",
    "print(\"___________________________________________________________________\")\n",
    "#Finally searching part!\n",
    "search_tweets(search_query, limitation,file_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "get_tweet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
